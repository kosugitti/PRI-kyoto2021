---
title: "Day 1;2021.02.24"
output: html_document
---

# Day 1

## RStudioを使ってコードを書く

### プロジェクトでの管理
### rの基礎


### Rの関数とデータの型

#### 四則演算
```{r}
1 + 3
3 - 5
5 * 7
8 / 2
```


#### 関数を使おう
```{r}
sqrt(4)
help(sqrt)
```

#### 代入

```{r}
obj <- 2
obj
obj2 <- 2
obj3 <- 3
obj2 + obj3
obj <- 1:10
obj
obj * 2
obj <- matrix(c(1:10), nrow = 5)
obj
```

##### 代入したものの操作
```{r}
obj * 2

obj[1, ]
obj[, 2]
```

#### なんでも入れれるlist型

```{r}
obj <- list(
  name = c("kosugi", "tanaka", "suzuki"),
  gender = c("male", "female", "male"),
  height = c(170, 160),
  weight = c(70.6, 80.9, 90.6, 40.3)
)
obj
```


##### 代入したものの操作
```{r}
obj$name
```


#### データの型
```{r}
str(obj)
```

##### 数字，文字，factor型
```{r}
obj$gender <- as.factor(obj$gender)
str(obj)
```

#### データフレーム型
```{r}
obj <- data.frame(
  list(
    name = c("kosugi", "tanaka", "suzuki"),
    gender = c(1, 2, 1),
    hight = c(170, 160, 170),
    weight = c(70.6, 80.9, 90.6)
  )
)
```

##### 代入したものの操作
```{r}
str(obj)
obj$gender <- factor(obj$gender, labels = c("male", "female"))
obj
```

### rstanを使ってみよう(8school)

```{r}
library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())

stancode <- "
data {
  int<lower=0> J; // number of schools 
  real y[J]; // estimated treatment effects
  real<lower=0> sigma[J]; // s.e. of effect estimates 
}
parameters {
  real mu; 
  real<lower=0> tau;
  real eta[J];
}
transformed parameters {
  real theta[J];
  for (j in 1:J)
  theta[j] = mu + tau * eta[j];
}
model {
  target += normal_lpdf(eta | 0, 1);
  target += normal_lpdf(y | theta, sigma);
}
"

schools_dat <- list(
  J = 8, y = c(28, 8, -3, 7, -1, 1, 18, 12),
  sigma = c(15, 10, 16, 11, 9, 11, 10, 18)
)

model.ex <- stan_model(model_code = stancode, model_name = "school")
fit.ML <- optimizing(model.ex, data = schools_dat)
fit.samp <- sampling(model.ex,
  data = schools_dat, iter = 1000,
  chains = 4
)
fit.vb <- vb(model.ex, data = schools_dat)
fit.ML
fit.samp
fit.vb
```



## MCMCで何を行っているか

#### MCMCの結果の確認

  + Rhat
  + Effective Sample Size

#### 可視化
  
```{r}
plot(fit.samp)
plot(fit.samp, show_density = TRUE)

library(bayesplot)
mcmc_areas(fit.samp)
mcmc_combo(fit.samp, pars = "mu")
mcmc_dens(fit.samp, pars = "mu")
mcmc_dens_chains(fit.samp, pars = "mu")
mcmc_areas_ridges(fit.samp, regex_pars = "^eta\\[", prob = 0.95, prob_outer = 1)
rhat(fit.samp)
mcmc_rhat(rhat(fit.samp))
traceplot(fit.samp, inc_warmup = T)

library(bayestestR)
hdi(fit.samp, ci = 0.90)
map_estimate(fit.samp)
```


## パラメータリカバリという考え方

→資料

## ベルヌーイ分布で遊んでみよう

```{r}
set.seed(12345)
N <- 100
theta <- 0.3
X <- rbinom(N, 1, theta)
X
mean(X)
```

```{r, echo=FALSE, eval=TRUE}
cat(paste(readLines("bernoulli.stan"), collapse = "\n"))
```

```{r}
# コンパイル
model.bern <- stan_model("bernoulli.stan", model_name = "sample1")
# データの準備
dataSet <- list(N = N, Y = X)
# サンプリング
fit <- sampling(model.bern, dataSet)
# 結果表示
fit
map_estimate(fit)
hdi(fit, ci = 0.9)
# 可視化
mcmc_dens(fit)
```

#### MCMCサンプルが増えるとどうなるか
```{r}
fit <- sampling(model.bern, dataSet, iter = 50000, chains = 3)
fit
map_estimate(fit)
```

#### データ数が変わるとどうなるか
```{r}
set.seed(12345)
N <- 10
theta <- 0.3
X <- rbinom(N, 1, theta)
X
mean(X)
dataSet <- list(N = N, Y = X)
fit <- sampling(model.bern, dataSet, iter = 50000, chains = 3)
fit
map_estimate(fit)
hdi(fit)
```
